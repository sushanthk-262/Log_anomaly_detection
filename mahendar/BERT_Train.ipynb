{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install transformers ##"
      ],
      "metadata": {
        "id": "MvNrvh4yN76L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkCdgozmMuvi"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dC8vnWOIOC79"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load file ##"
      ],
      "metadata": {
        "id": "cLbzCmN_OOMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/SMSSpamCollection\",sep=\"\\t\", names= [\"label\", \"message\"])\n",
        "df"
      ],
      "metadata": {
        "id": "fm0eC3s3Oj6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction ##"
      ],
      "metadata": {
        "id": "ZtasluMZQag8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X = list(df['message'])   Independent variables\n",
        "X = list(df['message'])\n",
        "X"
      ],
      "metadata": {
        "id": "uwJTpx0jQdUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = list(df['label'])\n",
        "y"
      ],
      "metadata": {
        "id": "Uo2NhZprQ71O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping ##"
      ],
      "metadata": {
        "id": "yLsO-nZWRCpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(y,drop_first=True)['spam']\n",
        "y"
      ],
      "metadata": {
        "id": "Y4OfyBRlRJKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split ##"
      ],
      "metadata": {
        "id": "o0UM5aEKRgLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "2asOMKEERjLb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Bert tokenizer ##"
      ],
      "metadata": {
        "id": "A5jmzNkxT46S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "BA7oVDh6T9uk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"bert-large-uncased\"\n",
        "# Load the BERT large tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "axdFidNTUE4-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get encodings ##\n",
        "train the features to the BERT model"
      ],
      "metadata": {
        "id": "oYpxzHBdUhZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "OShM6J23UoSp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_encodings\n",
        "#test_encodings"
      ],
      "metadata": {
        "id": "gMKF9sF5YCVD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert encodings into Dataset objects ##"
      ],
      "metadata": {
        "id": "lSa47FYEZa6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))"
      ],
      "metadata": {
        "id": "onYx_V9fZElz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset"
      ],
      "metadata": {
        "id": "SknJjWwDandL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import BERT model ##"
      ],
      "metadata": {
        "id": "saNSk2kicEed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  BertForMaskedLM, TFTrainer, TFTrainingArguments"
      ],
      "metadata": {
        "id": "bH-UQLjacMKM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=200,\n",
        ")"
      ],
      "metadata": {
        "id": "hqs2uRgKcv4t"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model with TFTrainer #"
      ],
      "metadata": {
        "id": "trwT8QFNPeq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with training_args.strategy.scope():\n",
        "   model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
        "\n",
        "trainer = TFTrainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "wm52c7Rud6as",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bbc198e-9ab2-4e03-bba1-9d23b24f96ed"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4319e8031035>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREFIX_CHECKPOINT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_total_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, **kwargs)\u001b[0m\n\u001b[1;32m   2175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mconverted_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m       \u001b[0m_assert_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36m_assert_trackable\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m   1529\u001b[0m   if not isinstance(\n\u001b[1;32m   1530\u001b[0m       obj, (base.Trackable, def_function.Function)):\n\u001b[0;32m-> 1531\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1532\u001b[0m         \u001b[0;34mf\"`Checkpoint` was expecting {name} to be a trackable object (an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;34mf\"object derived from `Trackable`), got {obj}. If you believe this \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `Checkpoint` was expecting model to be a trackable object (an object derived from `Trackable`), got BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n      (position_embeddings): Embedding(512, 1024)\n      (token_type_embeddings): Embedding(2, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n        (transform_act_fn): GELUActivation()\n        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=1024, out_features=30522, bias=True)\n    )\n  )\n). If you believe this object should be trackable (i.e. it is part of the TensorFlow Python API and manages state), please open an issue."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "og5tlhwSgDZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "7iVhlW_AgUoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = trainer.predict(test_dataset)[1]\n",
        "output"
      ],
      "metadata": {
        "id": "Q-o5erYngdJy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}