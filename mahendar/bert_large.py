# -*- coding: utf-8 -*-
"""bert_large.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PbRy-NvTnHMGZKU35mqJ7c-VOEpWfv0S

# Install Transformers #
"""

!pip install transformers

import pandas as pd

"""# Load File #"""

df = pd.read_csv("/content/SMSSpamCollection",sep="\t", names= ["label", "message"])
df

"""# Feature Extraction #"""

#X = list(df['message'])   Independent variables
X = list(df['message'])
X

y = list(df['label'])
y

"""# Mapping #"""

y = pd.get_dummies(y,drop_first=True)['spam']
y

"""# Train-Test split #"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)

"""# Import BertTokenizer #"""

from transformers import BertTokenizer

model_name="bert-large-uncased"
# Load the BERT large tokenizer
tokenizer = BertTokenizer.from_pretrained(model_name)

"""## Get encodings ##
train the features to the BERT model
"""

train_encodings = tokenizer(X_train, truncation=True, padding=True)
test_encodings = tokenizer(X_test, truncation=True, padding=True)

"""# Convert encodings into Datasets #"""

import tensorflow as tf
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    y_train
))
test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings),
    y_test
))

"""# Import Bert Large Model #"""

from transformers import  BertModel, TFTrainer, TFTrainingArguments

training_args = TFTrainingArguments(
    output_dir="./bert-large-imdb",
    num_train_epochs=3,
    evaluation_strategy="steps",
    eval_steps=500,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    learning_rate=2e-5,
    save_total_limit=2,
    save_steps=500,
    logging_steps=100,
    remove_unused_columns=False,
    push_to_hub=False,
    report_to="tensorboard",
)

"""# Train the model with Trainer #"""

with training_args.strategy.scope():
   model = BertModel.from_pretrained(model_name,from_tf=True)

trainer = TFTrainer(
    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained
    args=training_args,                  # training arguments, defined above
    train_dataset=train_dataset,         # training dataset
    eval_dataset=test_dataset             # evaluation dataset
)

trainer.train()

"""# Evaluation #"""

trainer.evaluate(test_dataset)

trainer.predict(test_dataset)

output = trainer.predict(test_dataset)[1]
output